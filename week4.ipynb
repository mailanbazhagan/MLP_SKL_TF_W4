{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data_preprocess():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Normalize images\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    # Flatten images\n",
    "    x_train = x_train.reshape(-1, 28 * 28)\n",
    "    x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train(model, x_train, y_train):\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=20,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history, model\n",
    "\n",
    "# Main program\n",
    "(x_train, y_train), (x_test, y_test) = load_data_preprocess()\n",
    "model = create_model()\n",
    "history, model = train(model, x_train, y_train)\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_true = np.argmax(y_test, axis=1)  # Convert one-hot to class indices\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Heatmap visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Load and Preprocess the CIFAR-10 Dataset\n",
    "def load_cifar10_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    # Normalize the images to [0, 1]\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    # Flatten the images\n",
    "    x_train = x_train.reshape(-1, 32 * 32 * 3)\n",
    "    x_test = x_test.reshape(-1, 32 * 32 * 3)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# Step 2: Create the MLP Model\n",
    "def create_mlp_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1024, activation='relu', input_shape=(32 * 32 * 3,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Train the Model\n",
    "def train_model(model, x_train, y_train):\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=20,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history, model\n",
    "\n",
    "# Step 4: Visualize Training Performance\n",
    "def plot_training_performance(history):\n",
    "    # Accuracy plot\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Step 5: Evaluate and Visualize Confusion Matrix\n",
    "def plot_confusion_matrix(model, x_test, y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # Confusion Matrix Heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Main Program\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10_data()\n",
    "model = create_mlp_model()\n",
    "history, model = train_model(model, x_train, y_train)\n",
    "plot_training_performance(history)\n",
    "plot_confusion_matrix(model, x_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
